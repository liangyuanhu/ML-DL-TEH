{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DeepSurv from the repo\n",
    "import sys\n",
    "sys.path.append('../deepsurv')\n",
    "import deep_surv\n",
    "\n",
    "from deepsurv_logger import DeepSurvLogger, TensorboardLogger\n",
    "import utils\n",
    "import viz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lasagne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,200):\n",
    "    train_dataset_fp_trt_1 = './data_gen_partial_censor_40_trt_1_'+str(i)+'.csv'\n",
    "    train_df_trt_1 = pd.read_csv(train_dataset_fp_trt_1)\n",
    "    train_dataset_fp_trt_0 = './data_gen_partial_censor_40_trt_0_'+str(i)+'.csv'\n",
    "    train_df_trt_0 = pd.read_csv(train_dataset_fp_trt_0)\n",
    "    \n",
    "    # event_col is the header in the df that represents the 'Event / Status' indicator\n",
    "    # time_col is the header in the df that represents the event time\n",
    "    def dataframe_to_deepsurv_ds(df, event_col = 'Event', time_col = 'Time'):\n",
    "    # Extract the event and time columns as numpy arrays\n",
    "    e = df[event_col].values.astype(np.int32)\n",
    "    t = df[time_col].values.astype(np.float32)\n",
    "\n",
    "    # Extract the patient's covariates as a numpy array\n",
    "    x_df = df.drop([event_col, time_col], axis = 1)\n",
    "    x = x_df.values.astype(np.float32)\n",
    "    \n",
    "    # Return the deep surv dataframe\n",
    "    return {\n",
    "        'x' : x,\n",
    "        'e' : e,\n",
    "        't' : t\n",
    "    }\n",
    "\n",
    "    # If the headers of the csv change, you can replace the values of \n",
    "    # 'event_col' and 'time_col' with the names of the new headers\n",
    "    # You can also use this function on your training dataset, validation dataset, and testing dataset\n",
    "    train_data_trt_1 = dataframe_to_deepsurv_ds(train_df_trt_1, event_col = 'Event', time_col= 'Time')\n",
    "    train_data_trt_0 = dataframe_to_deepsurv_ds(train_df_trt_0, event_col = 'Event', time_col= 'Time')\n",
    "    import theano\n",
    "    hyperparams_trt_1 = {\n",
    "    'L2_reg': 10.0,\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.4,\n",
    "    'hidden_layers_sizes': [25, 25],\n",
    "    'learning_rate': 1e-05,\n",
    "    'lr_decay': 0.001,\n",
    "    'momentum': 0.9,\n",
    "    'n_in': train_data_trt_1['x'].shape[1],\n",
    "    'standardize': False\n",
    "    }\n",
    "    \n",
    "    hyperparams_trt_0 = {\n",
    "    'L2_reg': 10.0,\n",
    "    'batch_norm': True,\n",
    "    'dropout': 0.4,\n",
    "    'hidden_layers_sizes': [25, 25],\n",
    "    'learning_rate': 1e-05,\n",
    "    'lr_decay': 0.001,\n",
    "    'momentum': 0.9,\n",
    "    'n_in': train_data_trt_0['x'].shape[1],\n",
    "    'standardize': False\n",
    "    }\n",
    "    \n",
    "    # Create an instance of DeepSurv using the hyperparams defined above\n",
    "    model_trt_1 = deep_surv.DeepSurv(**hyperparams_trt_1)\n",
    "    model_trt_0 = deep_surv.DeepSurv(**hyperparams_trt_0)\n",
    "    \n",
    "    compute_hazards_trt_1 = theano.function(inputs = [model_trt_1.X],outputs = model_trt_1.partial_hazard)\n",
    "    partial_hazards_trt_1_trt_1 = compute_hazards_trt_1(train_data_trt_1['x'])\n",
    "    partial_hazards_trt_1_trt_0 = compute_hazards_trt_1(train_data_trt_0['x'])\n",
    "    compute_hazards_trt_0 = theano.function(inputs = [model_trt_0.X],outputs = model_trt_0.partial_hazard)\n",
    "    partial_hazards_trt_0_trt_1 = compute_hazards_trt_0(train_data_trt_1['x'])\n",
    "    partial_hazards_trt_0_trt_0 = compute_hazards_trt_0(train_data_trt_0['x'])\n",
    "    np.savetxt('./partial_hazards_partial_censor_40_trt_1_trt_1_'+str(i)+'.csv', partial_hazards_trt_1_trt_1, delimiter=\",\")\n",
    "    np.savetxt('./partial_hazards_partial_censor_40_trt_1_trt_0_'+str(i)+'.csv', partial_hazards_trt_1_trt_0, delimiter=\",\")\n",
    "    np.savetxt('./partial_hazards_partial_censor_40_trt_0_trt_0_'+str(i)+'.csv', partial_hazards_trt_0_trt_0, delimiter=\",\")\n",
    "    np.savetxt('./partial_hazards_partial_censor_40_trt_0_trt_1_'+str(i)+'.csv', partial_hazards_trt_0_trt_1, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
